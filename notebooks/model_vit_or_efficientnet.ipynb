{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 05_model_vit_or_efficientnet.ipynb\n\n**EfficientNet or Vision Transformer (ViT)** for Driver Drowsiness Detection.\n\n- Uses your preprocessed arrays in `data/processed/*.npy`\n- Choose model via `MODEL_FAMILY = \"efficientnet\"` or `\"vit\"`\n- Handles resizing & preprocessing internally\n- Trains, evaluates, saves model + report\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import os, json, time, numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Paths\nPROCESSED_DIR = \"data/processed\"\nMODEL_DIR     = \"models\"\nRESULTS_DIR   = \"results\"\nos.makedirs(MODEL_DIR, exist_ok=True)\nos.makedirs(RESULTS_DIR, exist_ok=True)\n\n# Classes\nCLASS_NAMES = [\"Closed_Eyes\",\"Open_Eyes\",\"Yawn\",\"No_Yawn\"]\nnum_classes = len(CLASS_NAMES)\n\n# Choose family: 'efficientnet' or 'vit'\nMODEL_FAMILY = \"efficientnet\"  # change to 'vit' if you want Vision Transformer\n\n# Target image size\nTARGET_SIZE = (224, 224)\n\ntf.random.set_seed(42); np.random.seed(42)\nprint(\"TensorFlow:\", tf.__version__, \"| Model family:\", MODEL_FAMILY, \"| Target:\", TARGET_SIZE)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "X_train = np.load(f\"{PROCESSED_DIR}/X_train.npy\")\ny_train = np.load(f\"{PROCESSED_DIR}/y_train.npy\")\nX_val   = np.load(f\"{PROCESSED_DIR}/X_val.npy\")\ny_val   = np.load(f\"{PROCESSED_DIR}/y_val.npy\")\nX_test  = np.load(f\"{PROCESSED_DIR}/X_test.npy\")\ny_test  = np.load(f\"{PROCESSED_DIR}/y_test.npy\")\n\nprint(\"Shapes:\")\nprint(\"  X_train:\", X_train.shape, \" y_train:\", y_train.shape)\nprint(\"  X_val  :\", X_val.shape,   \" y_val  :\", y_val.shape)\nprint(\"  X_test :\", X_test.shape,  \" y_test :\", y_test.shape)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "classes = np.arange(num_classes)\nclass_weights = compute_class_weight(\"balanced\", classes=classes, y=y_train)\nclass_weights = {int(i): float(w) for i,w in enumerate(class_weights)}\nclass_weights\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def build_efficientnet_classifier(num_classes, target_size=(224,224)):\n    resize = layers.Resizing(target_size[0], target_size[1])\n    preprocess = tf.keras.applications.efficientnet.preprocess_input\n    base = tf.keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(target_size[0], target_size[1], 3))\n    base.trainable = False  # Phase 1: feature extract\n\n    inputs = layers.Input(shape=X_train.shape[1:])  # e.g., (64,64,3)\n    x = resize(inputs)\n    x = layers.Lambda(preprocess)(x)\n    x = base(x, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.25)(x)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n    model = models.Model(inputs, outputs, name=\"efficientnet_b0_cls\")\n    return model, base\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def mlp(x, hidden_units, dropout=0.0):\n    for units in hidden_units:\n        x = layers.Dense(units, activation='gelu')(x)\n        x = layers.Dropout(dropout)(x)\n    return x\n\ndef build_vit_classifier(num_classes, image_size=(224,224), patch_size=16, projection_dim=192, transformer_layers=6, num_heads=3, mlp_head_units=[256,128]):\n    # Inputs come at original size; we resize to image_size\n    inputs = layers.Input(shape=X_train.shape[1:])  # (H0,W0,3)\n    x = layers.Resizing(image_size[0], image_size[1])(inputs)\n\n    # Patchify via Conv2D with stride = patch_size\n    patches = layers.Conv2D(filters=projection_dim, kernel_size=patch_size, strides=patch_size, padding=\"valid\")(x)  # (H/ps, W/ps, dim)\n    h, w = image_size[0] // patch_size, image_size[1] // patch_size\n    num_patches = h * w\n    x = layers.Reshape((num_patches, projection_dim))(patches)  # (B, N, D)\n\n    # Class token\n    cls_token = tf.Variable(tf.zeros((1, 1, projection_dim)), trainable=True, name=\"cls_token\")\n    cls_tokens = tf.repeat(cls_token, repeats=tf.shape(x)[0], axis=0)\n    x = tf.concat([cls_tokens, x], axis=1)  # (B, N+1, D)\n\n    # Positional embeddings\n    pos_emb = tf.Variable(tf.random.normal([1, num_patches + 1, projection_dim], stddev=0.02), trainable=True, name=\"pos_emb\")\n    x = x + pos_emb\n\n    # Transformer encoder blocks\n    for _ in range(transformer_layers):\n        # LayerNorm + MHA\n        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n        attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim, dropout=0.0)(x1, x1)\n        x2 = layers.Add()([attn, x])\n        # LayerNorm + MLP\n        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n        x3 = mlp(x3, hidden_units=[projection_dim*4, projection_dim], dropout=0.1)\n        x = layers.Add()([x3, x2])\n\n    # Take CLS token output\n    x = layers.LayerNormalization(epsilon=1e-6)(x)\n    cls_out = x[:, 0]  # (B, D)\n\n    # Head\n    x = mlp(cls_out, mlp_head_units, dropout=0.2)\n    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n    model = models.Model(inputs, outputs, name=\"vit_classifier\")\n    return model\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "if MODEL_FAMILY == \"efficientnet\":\n    model, base = build_efficientnet_classifier(num_classes, TARGET_SIZE)\nelse:\n    model = build_vit_classifier(num_classes, image_size=TARGET_SIZE)\nmodel.summary()\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n\nrun_id = time.strftime(\"%Y%m%d-%H%M%S\") + f\"_{MODEL_FAMILY}\"\nckpt_path = f\"{MODEL_DIR}/{MODEL_FAMILY}_best_{run_id}.keras\"\nlog_dir   = f\"{RESULTS_DIR}/logs_{run_id}\"\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n              loss=\"sparse_categorical_crossentropy\",\n              metrics=[\"accuracy\"])\n\ncallbacks = [\n    EarlyStopping(monitor=\"val_accuracy\", patience=8, restore_best_weights=True, verbose=1),\n    ModelCheckpoint(ckpt_path, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n    TensorBoard(log_dir=log_dir)\n]\n\nprint(\"Checkpoint:\", ckpt_path)\nprint(\"Logs     :\", log_dir)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "history1 = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=15 if MODEL_FAMILY==\"efficientnet\" else 25,\n    batch_size=64,\n    callbacks=callbacks,\n    class_weight=compute_class_weight(\"balanced\", classes=np.arange(num_classes), y=y_train),\n    verbose=1\n)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "history2 = None\nif MODEL_FAMILY == \"efficientnet\":\n    # Unfreeze last blocks for fine-tuning\n    for layer in base.layers[-30:]:\n        layer.trainable = True\n    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n                  loss=\"sparse_categorical_crossentropy\",\n                  metrics=[\"accuracy\"])\n    history2 = model.fit(\n        X_train, y_train,\n        validation_data=(X_val, y_val),\n        epochs=25,\n        batch_size=64,\n        callbacks=callbacks,\n        class_weight=compute_class_weight(\"balanced\", classes=np.arange(num_classes), y=y_train),\n        verbose=1\n    )\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def plot_hist(h, label):\n    if h is None: return\n    plt.figure(); plt.plot(h.history[\"accuracy\"], label=f\"{label} train\"); plt.plot(h.history[\"val_accuracy\"], label=f\"{label} val\"); plt.title(\"Accuracy\"); plt.xlabel(\"epoch\"); plt.legend(); plt.show()\n    plt.figure(); plt.plot(h.history[\"loss\"], label=f\"{label} train\"); plt.plot(h.history[\"val_loss\"], label=f\"{label} val\"); plt.title(\"Loss\"); plt.xlabel(\"epoch\"); plt.legend(); plt.show()\n\nplot_hist(history1, \"phase1\")\nplot_hist(history2, \"finetune\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"Test accuracy: {test_acc:.4f}\")\n\ny_prob = model.predict(X_test, verbose=0)\ny_pred = np.argmax(y_prob, axis=1)\n\nprint(classification_report(y_test, y_pred, target_names=CLASS_NAMES))\n\ncm = confusion_matrix(y_test, y_pred)\n\n# Matplotlib-only confusion matrix\nfig, ax = plt.subplots(figsize=(5,4))\nim = ax.imshow(cm, cmap=\"Blues\")\nax.set_xticks(range(num_classes)); ax.set_xticklabels(CLASS_NAMES, rotation=45, ha=\"right\")\nax.set_yticks(range(num_classes)); ax.set_yticklabels(CLASS_NAMES)\nfor i in range(num_classes):\n    for j in range(num_classes):\n        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\nax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(\"Confusion Matrix\")\nplt.colorbar(im, ax=ax); plt.tight_layout(); plt.show()\n\nreport_path = f\"{RESULTS_DIR}/{MODEL_FAMILY}_report_{run_id}.txt\"\nwith open(report_path, \"w\") as f:\n    f.write(f\"Test accuracy: {test_acc:.4f}\\n\\n\")\n    f.write(classification_report(y_test, y_pred, target_names=CLASS_NAMES))\nprint(\"Saved report to:\", report_path)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "final_path = f\"{MODEL_DIR}/{MODEL_FAMILY}_final_{run_id}.keras\"\nmodel.save(final_path)\nwith open(f\"{MODEL_DIR}/labels.json\",\"w\") as fp:\n    json.dump({i:c for i,c in enumerate(CLASS_NAMES)}, fp)\n\nprint(\"Saved model to:\", final_path)\nprint(\"Saved labels to: models/labels.json\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import cv2\ndef predict_image_generic(path, model, target_size=(224,224)):\n    img = cv2.imread(path)\n    if img is None: raise FileNotFoundError(path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, target_size)\n    x = (img/255.0).astype(\"float32\")\n    x = np.expand_dims(x, axis=0)\n    probs = model.predict(x, verbose=0)[0]\n    idx = int(np.argmax(probs))\n    return {\"class\": CLASS_NAMES[idx], \"confidence\": float(probs[idx]), \"probs\": probs.tolist()}\n\n# Example:\n# res = predict_image_generic(\"data/sample/your_image.jpg\", model, target_size=TARGET_SIZE)\n# res\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}