{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04_model_cnn_lstm.ipynb\n",
        "\n",
        "CNN-LSTM (sequence model) for Driver Drowsiness Detection.\n",
        "\n",
        "- Loads preprocessed frame arrays (data/processed/*.npy)\n",
        "- Synthesizes short sequences (T frames) per class from the image dataset\n",
        "- Builds a TimeDistributed CNN + LSTM classifier\n",
        "- Trains, evaluates, saves results and the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96c63dc",
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv (Python 3.13.2)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/HP/Desktop/DL Assignment/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "pip install opencv-python numpy pandas scikit-learn matplotlib tensorflow keras tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv (Python 3.13.2)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"c:/Users/HP/Desktop/DL Assignment/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import os, json, time, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Paths\n",
        "PROCESSED_DIR = \"../data/processed\"\n",
        "MODEL_DIR     = \"models\"\n",
        "RESULTS_DIR   = \"results\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Classes\n",
        "CLASS_NAMES = [\"Closed_Eyes\",\"Open_Eyes\",\"Yawn\",\"No_Yawn\"]\n",
        "num_classes = len(CLASS_NAMES)\n",
        "\n",
        "# Reproducibility\n",
        "tf.random.set_seed(42); np.random.seed(42)\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessed single frames\n",
        "X_train = np.load(f\"{PROCESSED_DIR}/X_train.npy\")\n",
        "y_train = np.load(f\"{PROCESSED_DIR}/y_train.npy\")\n",
        "X_val   = np.load(f\"{PROCESSED_DIR}/X_val.npy\")\n",
        "y_val   = np.load(f\"{PROCESSED_DIR}/y_val.npy\")\n",
        "X_test  = np.load(f\"{PROCESSED_DIR}/X_test.npy\")\n",
        "y_test  = np.load(f\"{PROCESSED_DIR}/y_test.npy\")\n",
        "\n",
        "H,W,C = X_train.shape[1:]\n",
        "print(\"Frames loaded:\")\n",
        "print(\"  Train:\", X_train.shape, \" Val:\", X_val.shape, \" Test:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sequence synthesis settings\n",
        "T = 8                      # sequence length\n",
        "STRATEGY = \"random\"        # 'random' | 'block'\n",
        "SEQS_PER_CLASS_TRAIN = 400  # caps (auto-adjusted)\n",
        "SEQS_PER_CLASS_VAL   = 120\n",
        "SEQS_PER_CLASS_TEST  = 120\n",
        "\n",
        "def index_by_class(y):\n",
        "    buckets = defaultdict(list)\n",
        "    for idx, label in enumerate(y):\n",
        "        buckets[int(label)].append(idx)\n",
        "    return buckets\n",
        "\n",
        "def build_sequences_from_frames(X, y, T, seqs_per_class, strategy=\"random\"):\n",
        "    buckets = index_by_class(y)\n",
        "    X_seqs, y_seqs = [], []\n",
        "    for cls, idxs in buckets.items():\n",
        "        idxs = np.array(idxs)\n",
        "        n_avail = len(idxs)\n",
        "        n_make = min(seqs_per_class, max(1, n_avail // max(1, T//2)))\n",
        "        for _ in range(n_make):\n",
        "            if strategy == \"random\":\n",
        "                chosen = np.random.choice(idxs, size=T, replace=True)\n",
        "            else:\n",
        "                np.random.shuffle(idxs)\n",
        "                start = np.random.randint(0, max(1, len(idxs)-T+1))\n",
        "                chosen = idxs[start:start+T]\n",
        "                if len(chosen) < T:\n",
        "                    chosen = np.pad(chosen, (0, T-len(chosen)), mode=\"edge\")\n",
        "            seq = X[chosen]\n",
        "            X_seqs.append(seq)\n",
        "            y_seqs.append(cls)\n",
        "    X_seqs = np.array(X_seqs, dtype=X.dtype)\n",
        "    y_seqs = np.array(y_seqs, dtype=np.int64)\n",
        "    return X_seqs, y_seqs\n",
        "\n",
        "# Build sequences for each split\n",
        "Xtr_seq, ytr_seq = build_sequences_from_frames(X_train, y_train, T, SEQS_PER_CLASS_TRAIN, STRATEGY)\n",
        "Xva_seq, yva_seq = build_sequences_from_frames(X_val,   y_val,   T, SEQS_PER_CLASS_VAL,   STRATEGY)\n",
        "Xte_seq, yte_seq = build_sequences_from_frames(X_test,  y_test,  T, SEQS_PER_CLASS_TEST,  STRATEGY)\n",
        "\n",
        "print(\"Sequences built:\")\n",
        "print(\"  Train:\", Xtr_seq.shape, \" Val:\", Xva_seq.shape, \" Test:\", Xte_seq.shape)\n",
        "print(\"  Class dist (train):\", Counter(ytr_seq))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classes = np.arange(num_classes)\n",
        "class_weights = compute_class_weight(\"balanced\", classes=classes, y=ytr_seq)\n",
        "class_weights = {int(i): float(w) for i,w in enumerate(class_weights)}\n",
        "class_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_cnn_backbone(input_shape_frame=(64,64,3)):\n",
        "    inp = layers.Input(shape=input_shape_frame)\n",
        "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inp)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)  # (F,)\n",
        "    return models.Model(inp, x, name=\"frame_cnn\")\n",
        "\n",
        "frame_cnn = build_cnn_backbone((H,W,C))\n",
        "\n",
        "seq_input = layers.Input(shape=(None, H, W, C))  # (T,H,W,C)\n",
        "x = layers.TimeDistributed(frame_cnn)(seq_input)  # (T, F)\n",
        "x = layers.LSTM(128, return_sequences=False)(x)\n",
        "x = layers.Dropout(0.35)(x)\n",
        "out = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = models.Model(seq_input, out, name=\"cnn_lstm\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "run_id = time.strftime(\"%Y%m%d-%H%M%S\") + \"_cnnlstm\"\n",
        "ckpt_path = f\"{MODEL_DIR}/cnn_lstm_best_{run_id}.keras\"\n",
        "log_dir   = f\"{RESULTS_DIR}/logs_{run_id}\"\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_accuracy\", patience=8, restore_best_weights=True, verbose=1),\n",
        "    ModelCheckpoint(ckpt_path, monitor=\"val_accuracy\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
        "    TensorBoard(log_dir=log_dir)\n",
        "]\n",
        "\n",
        "print(\"Checkpoint:\", ckpt_path)\n",
        "print(\"Logs     :\", log_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    Xtr_seq, ytr_seq,\n",
        "    validation_data=(Xva_seq, yva_seq),\n",
        "    epochs=35,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h = history.history\n",
        "plt.figure(); plt.plot(h[\"accuracy\"], label=\"train\"); plt.plot(h[\"val_accuracy\"], label=\"val\");\n",
        "plt.title(\"Accuracy\"); plt.xlabel(\"epoch\"); plt.legend(); plt.show()\n",
        "plt.figure(); plt.plot(h[\"loss\"], label=\"train\"); plt.plot(h[\"val_loss\"], label=\"val\");\n",
        "plt.title(\"Loss\"); plt.xlabel(\"epoch\"); plt.legend(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(Xte_seq, yte_seq, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "y_prob = model.predict(Xte_seq, verbose=0)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "print(classification_report(yte_seq, y_pred, target_names=CLASS_NAMES))\n",
        "\n",
        "cm = confusion_matrix(yte_seq, y_pred)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,4))\n",
        "im = ax.imshow(cm, cmap=\"Blues\")\n",
        "ax.set_xticks(range(num_classes)); ax.set_xticklabels(CLASS_NAMES, rotation=45, ha=\"right\")\n",
        "ax.set_yticks(range(num_classes)); ax.set_yticklabels(CLASS_NAMES)\n",
        "for i in range(num_classes):\n",
        "    for j in range(num_classes):\n",
        "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
        "ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(\"Confusion Matrix\")\n",
        "plt.colorbar(im, ax=ax); plt.tight_layout(); plt.show()\n",
        "\n",
        "report_path = f\"{RESULTS_DIR}/cnn_lstm_report_{run_id}.txt\"\n",
        "with open(report_path, \"w\") as f:\n",
        "    f.write(f\"Test accuracy: {test_acc:.4f}\\n\\n\")\n",
        "    f.write(classification_report(yte_seq, y_pred, target_names=CLASS_NAMES))\n",
        "print(\"Saved report to:\", report_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_path = f\"{MODEL_DIR}/cnn_lstm_final_{run_id}.keras\"\n",
        "model.save(final_path)\n",
        "with open(f\"{MODEL_DIR}/labels.json\",\"w\") as fp:\n",
        "    json.dump({i:c for i,c in enumerate(CLASS_NAMES)}, fp)\n",
        "\n",
        "print(\"Saved model to:\", final_path)\n",
        "print(\"Saved labels to: models/labels.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def load_img_rgb(path, target=(64,64)):\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, target)\n",
        "    return (img/255.0).astype(\"float32\")\n",
        "\n",
        "def predict_sequence(paths, model, target=(64,64)):\n",
        "    frames = np.stack([load_img_rgb(p, target) for p in paths], axis=0)  # (T,H,W,C)\n",
        "    x = np.expand_dims(frames, axis=0)  # (1,T,H,W,C)\n",
        "    probs = model.predict(x, verbose=0)[0]\n",
        "    idx = int(np.argmax(probs))\n",
        "    return {\"class\": CLASS_NAMES[idx], \"confidence\": float(probs[idx]), \"probs\": probs.tolist()}\n",
        "\n",
        "# Example:\n",
        "# seq_paths = [ \"data/sample/closed1.jpg\", \"data/sample/closed2.jpg\", ... ]  # length T\n",
        "# res = predict_sequence(seq_paths, model); res\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
